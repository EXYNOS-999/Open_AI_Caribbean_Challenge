<?xml version="1.0" encoding="UTF-8"?><w:document xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main"><w:body><w:p><w:pPr><w:pStyle w:val="title"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Open AI Caribbean Challenge: Mapping Disaster Risk from Aerial Imagery </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Getting Started with MATLAB</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Hello all! We at MathWorks, in collaboration with DrivenData, are excited to bring you this challenge. Through this challenge we plan to provide you the real-world experience of working with a dataset of drone aerial imagery (big images) for classification. We also encourage you to use MATLAB and its various toolboxes to train your model.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>This challenge focuses on the disaster risk management of cities which are prone to natural hazards. You are provided with large aerial images captured by drones of regions in Colombia, St. Lucia, and St. Guatemala. The data includes aerial imagery and GeoJSON files including the building footprint, unique building ID, and roof material labels (for the training data).</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>The dataset is around 30GB in total. Within it there are 3 folders for each country - Colombia, Guatemala, and St. Lucia. Each country's folder consists of subfolders of areas/regions. For instance, within "Colombia" we have 2 regions named </w:t></w:r><w:r><w:rPr><w:b/></w:rPr><w:t>"borde_rural"</w:t></w:r><w:r><w:t> and </w:t></w:r><w:r><w:rPr><w:b/></w:rPr><w:t>"borde_soacha"</w:t></w:r><w:r><w:t>. Each region's folder has </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="ListParagraph"/><w:numPr><w:numId w:val="1"/></w:numPr><w:jc w:val="left"/></w:pPr><w:r><w:t>A BigTIFF image file of the region -- for example, </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>borde_rural_ortho-cog.tif</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="ListParagraph"/><w:numPr><w:numId w:val="1"/></w:numPr><w:jc w:val="left"/></w:pPr><w:r><w:t>GeoJSON files with metadata on the image extent in latitude/longitude, training data, and test data</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Below we are providing a basic Benchmark starter code in MATLAB. In this code we will walk through a basic classification model, where we are training a deep neural network classifier using transfer learning on a pretrained model. Then, we are using this model predict building materials on test data and saving a CSV file in the format required for the challenge. </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>This should serve as basic code where you can start analyzing the data and work towards developing a more efficient, optimized, and accurate model using more of the training data available.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>On the challenge's </w:t></w:r><w:hyperlink w:docLocation="https://www.drivendata.org/competitions/58/disaster-response-roof-type/page/143/"><w:r><w:t>Problem Description</w:t></w:r></w:hyperlink><w:r><w:t> page, all required details for images, features, labels and submission metrics are provided.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>So, let's get started with this dataset!</w:t></w:r></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="center"/></w:pPr><w:r><w:t>LOADING AND PREPARING DATA</w:t></w:r></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Load the data as a bigimage</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>We are adding the path of the data folder </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>stac</w:t></w:r><w:r><w:t> and an array of strings of the two region names we are training on. As you will be training on all the regions either you can add the names of all the regions on the array or for a more efficient way to work is through reterieving files within the subfolders. </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[addpath(genpath("stac")); % Change to whichever folder on your machine contains the dataset
regionNames = ["borde_rural","borde_soacha"];]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:hyperlink w:docLocation="https://www.mathworks.com/help/images/ref/bigimage.html"><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>bigimage</w:t></w:r></w:hyperlink><w:r><w:t> is a new Image Processing Toolbox function in MATLAB R2019b for processing very large images that may not fit in memory. So here we are creating bigimage objects for the BigTIFF image of each region. </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[for idx = 1:numel(regionNames)
    bimg = bigimage(which(regionNames(idx) + "_ortho-cog.tif"));]]></w:t></w:r></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Split the image into the RGB channel and the mask</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Once we have our </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>bigimage</w:t></w:r><w:r><w:t> we notice that the image has 4 channels - 3 channels of RGB and a 4th mask channel of opacity. With the use of the helper function </w:t></w:r><w:hyperlink w:anchor="internal:354E232C"><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>separateChannels</w:t></w:r></w:hyperlink><w:r><w:t> we are removing the opacity mask channel. For further training we will only be using the 3 RGB channels. </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>NOTE: This will take some time to process. You can set the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>UseParallel</w:t></w:r><w:r><w:t> flag to </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>true</w:t></w:r><w:r><w:t>, which will speed things by starting a parallel pool that uses multiple CPU cores on your machine.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    brgb(idx) = apply(bimg,1, @separateChannels,'UseParallel',true);]]></w:t></w:r></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Set the spatial reference for the bigimage</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Since each region's image spans a rectangular region with a particular latitude and longitude extent, we want to assign this as the spatial reference for the image. This will allow us to extract image regions by using the latitude and longitude value rather than the pixel values, which we will need to do later.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>For more information, refer to the </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/images/set-spatial-referencing-for-big-image.html"><w:r><w:t>Set Spatial Referencing for Big Images</w:t></w:r></w:hyperlink><w:r><w:t> example in the documentation.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Parse the GeoJSON files providing the bounding box of the entire region</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    fid = fopen(regionNames(idx) + "-imagery.json");
    imageryStructs(idx) = jsondecode(fread(fid,inf,'*char')');
    fclose(fid);]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Use the bounding boxes parsed out to set the X and Y world limits to the longitude and latitude extents</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    for k = 1:numel(brgb(idx).SpatialReferencing)
        brgb(idx).SpatialReferencing(k).XWorldLimits = [imageryStructs(idx).bbox(1) imageryStructs(idx).bbox(3)]; % Longitude limits
        brgb(idx).SpatialReferencing(k).YWorldLimits = [imageryStructs(idx).bbox(2) imageryStructs(idx).bbox(4)]; % Latitude limits
    end
    
end
clear bimg]]></w:t></w:r></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Create Training Data</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>The training set consists of 3 pieces of information that can be parsed from the GeoJSON files for each region</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="ListParagraph"/><w:numPr><w:numId w:val="2"/></w:numPr><w:jc w:val="left"/></w:pPr><w:r><w:t>The building ID</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="ListParagraph"/><w:numPr><w:numId w:val="2"/></w:numPr><w:jc w:val="left"/></w:pPr><w:r><w:t>The building polygon coordinates (in latitude-longitude points)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="ListParagraph"/><w:numPr><w:numId w:val="2"/></w:numPr><w:jc w:val="left"/></w:pPr><w:r><w:t>The building material</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>To extract the training set, we are opening the GeoJSON file of each region, reading it, and decoding the files using the </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/matlab/ref/jsondecode.html"><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>jsondecode</w:t></w:r></w:hyperlink><w:r><w:t> function.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[for idx = 1:numel(regionNames)    
    fid = fopen("train-" + regionNames(idx) + ".geojson");
    trainingStructs(idx) = jsondecode(fread(fid,inf,'*char')');
    fclose(fid);
end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Once we have all the values in the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>trainingStructs</w:t></w:r><w:r><w:t> array we will concatenate all the structures together and get a total number of training set elements.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[numTrainRegions = arrayfun(@(x)sum(length(x.features)), trainingStructs);
numTrainRegionsCumulative = cumsum(numTrainRegions);
numTrain = sum(numTrainRegions);
trainingStruct = cat(1, trainingStructs.features);]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Now let's create placeholder arrays for the ID, material, and coordinates</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[trainID = cell(numTrain,1);         % Training data ID
trainMaterial = cell(numTrain,1);   % Training data material
trainCoords = cell(numTrain,1);     % Training data coordinates]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>  Loop through all training data elements</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[regionIdx = 1;
for k = 1:numTrain]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>  Extract the ID, material, and coordinates of each ROI</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    trainID{k} = trainingStruct(k).id;
    trainMaterial{k} = trainingStruct(k).properties.roof_material;
    coords = trainingStruct(k).geometry.coordinates;
    if iscell(coords)
        coords = coords{1};
    end
    trainCoords{k} = squeeze(coords);    ]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Increment the index of regions as we loop through the training set to ensure we are referring to the correct region</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    if k > numTrainRegionsCumulative(regionIdx)
        regionIdx = regionIdx + 1;
    end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Correct for coordinate convention by flipping the Y image coordinates of the building region coordinates</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    trainCoords{k}(:,2) = brgb(regionIdx).SpatialReferencing(1).YWorldLimits(2)-(trainCoords{k}(:,2)-brgb(regionIdx).SpatialReferencing(1).YWorldLimits(1));
end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Convert the text array of materials to a categorical array for later classification.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[trainMaterial = categorical(trainMaterial);]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Clear the training data structures since they have now been parsed into individual arrays.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[clear trainingStruct trainingStructs]]></w:t></w:r></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:rPr><w:b/></w:rPr><w:t>OPTIONAL: Visualize the Training Data</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>First, let's visualize a specific region and annotate all the training samples as regions of interest (ROIs). Generating the thousands of polygons and displaying them along with a large image is a graphics and computation intensive process, so it will take some time to run this section.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>To execute the following steps, change the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>display</w:t></w:r><w:r><w:t> flag value to </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>true</w:t></w:r><w:r><w:t>. You can also set the </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[display = false;]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>For more information, refer to the </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/images/extract-big-image-training-data-using-bigimagedatastore.html"><w:r><w:t>Extract Training Samples from Big Image</w:t></w:r></w:hyperlink><w:r><w:t> example in the documentation.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[displayRegion = "borde_rural";
displayRegionNum = find(regionNames==displayRegion);

if  display
    % Find the indices of the overall training structure that correspond to the selected region
    if displayRegionNum == 1
        polyIndices = 1:numTrainRegions(displayRegionNum);
    else
        polyIndices = numTrainRegions(displayRegionNum-1) + 1:numTrainRegions(displayRegionNum);
    end
    
    % Extract the ROI polygons
    polyFcn = @(position) images.roi.Polygon('Position',position);
    polys = cellfun(polyFcn,trainCoords(polyIndices));
    
    % Display the image with ROIs and label the plot
    figure
    bigimageshow(brgb(displayRegionNum))
    xlabel('Longitude')
    ylabel('Latitude')
    set(polys,'Visible','on')
    set(polys,'Parent',gca)
    set(polys,'Color','r')]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="center"/></w:pPr><w:r><w:rPr><w:i/></w:rPr><w:t>[Left] Image of one region with training set ROIs  [Right] Zoomed-in image region in the highlighted region on the left image</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="center"/></w:pPr><w:r><w:t>              </w:t></w:r><w:customXml w:element="image"><w:customXmlPr><w:attr w:name="height" w:val="-1"/><w:attr w:name="width" w:val="-1"/><w:attr w:name="relationshipId" w:val="rId1"/></w:customXmlPr></w:customXml><w:r><w:t>                                           </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>In the following code, we are extracting a few ROIs from the training set at random to verify that the roof regions have been extracted correctly.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    figure
    displayIndices = randi(numTrainRegions(displayRegionNum),4,1);
    for k = 1:numel(displayIndices)
        coords = trainCoords{displayIndices(k) + polyIndices(1) - 1};
        regionImg = getRegion(brgb(displayRegionNum),1, ...
            [min(coords(:,1)) min(coords(:,2))],[max(coords(:,1)) max(coords(:,2))]);
        subplot(2,2,k)
        imshow(regionImg);
    end
end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="center"/></w:pPr><w:r><w:rPr><w:i/></w:rPr><w:t>Sample ROIs extracted from the training set</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="center"/></w:pPr><w:customXml w:element="image"><w:customXmlPr><w:attr w:name="height" w:val="-1"/><w:attr w:name="width" w:val="-1"/><w:attr w:name="relationshipId" w:val="rId2"/></w:customXmlPr></w:customXml></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Save Training Data</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Now that we have all the training data, we will extract each building to a separate small image file and place it in a </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>training_data</w:t></w:r><w:r><w:t> folder with subfolders for each material. This will make things easy to set up for training a classification model, as you will see later.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>There are also ways to use </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/matlab/ref/datastore.html"><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>datastore</w:t></w:r></w:hyperlink><w:r><w:t> so you don't have to save all the images separately to disk, thus reducing the overhead of generating the training set up front. Instead, you can read chunks from each region's image file only as needed during training. This will likely be slower during training time, but you are welcome to explore this approach if you would like.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>If the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>training_data</w:t></w:r><w:r><w:t> folder already exists, skip this step and simply load the saved training data</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[if exist("training_data","dir")  
    load(fullfile("training_data","training_data"));]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Else, create a new folder with all the training data, including subfolders for each material label.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>NOTE: If you are changing the training set (e.g. changing the number of regions), we recommend deleting any existing </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>training_data</w:t></w:r><w:r><w:t> folder to force the folder to be recreated.       </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[else
    mkdir("training_data")
    cd training_data
    
    materialCategories = categories(trainMaterial);
    for k = 1:numel(materialCategories)
        mkdir(materialCategories{k})
    end
    cd ..]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Extract training images based on the ROIs and save each image to its corresponding material subfolder (NOTE: This will take some time)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    regionIdx = 1;
    for k = 1:numTrain]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Increment the index of regions as we loop through the training set to ensure we are referring to the correct image file when extracting regions.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[        if k > numTrainRegionsCumulative(regionIdx)
            regionIdx = regionIdx + 1;
        end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>In this step, we are simply getting the lower left and upper right coordinates of the building polygon and cropping out a rectangular region, but you may feel free to try other ways to manipulate the image to extract individual buildings for training.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[        coords = trainCoords{k};
        regionImg = getRegion(brgb(regionIdx),1,[min(coords(:,1)) min(coords(:,2))],[max(coords(:,1)) max(coords(:,2))]);
        imgFilename = fullfile("training_data", string(trainMaterial(k)) , trainID{k}+".png" );
        imwrite(regionImg,imgFilename);
    end ]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Save the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>trainID</w:t></w:r><w:r><w:t>, </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>trainMaterial</w:t></w:r><w:r><w:t>, and </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>trainCoords</w:t></w:r><w:r><w:t> variables to a MAT-file to refer to them later without regenerating all the training data.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    save(fullfile("training_data","training_data"),"trainID","trainMaterial","trainCoords")
end]]></w:t></w:r></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Create and Save Test Data</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Just as we did with the training data, we will now parse the test data GeoJSON files and save the data and images to a </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>test_data</w:t></w:r><w:r><w:t> folder.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>The test set consists of 2 pieces of information that can be parsed from the GeoJSON files for each region</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="ListParagraph"/><w:numPr><w:numId w:val="2"/></w:numPr><w:jc w:val="left"/></w:pPr><w:r><w:t>The building ID</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="ListParagraph"/><w:numPr><w:numId w:val="2"/></w:numPr><w:jc w:val="left"/></w:pPr><w:r><w:t>The building polygon coordinates (in latitude-longitude points)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>If the folder already exists, skip this step and simply load the saved test data</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[if exist("test_data","dir")  
    load(fullfile("test_data","test_data"));]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Else, create a new folder with all the test data.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>NOTE: If you are changing the test set (e.g. changing the number of regions), we recommend deleting any existing </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>test_data</w:t></w:r><w:r><w:t> folder to force the folder to be recreated.       </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[else
    mkdir("test_data")]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>First, we will set up </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>bigimage</w:t></w:r><w:r><w:t> variables for all regions with test labels (which are all except Castries and Gros Islet). You won't have to redo this step if these are the same regions you used for training.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    regionNames = ["borde_rural","borde_soacha","mixco_1_and_ebenezer","mixco_3","dennery"];
    for idx = 1:numel(regionNames)
        bimg = bigimage(which(regionNames(idx) + "_ortho-cog.tif"));
        brgb(idx) = apply(bimg,1, @separateChannels,'UseParallel',true);
        fid = fopen(regionNames(idx) + "-imagery.json");
        imageryStructs(idx) = jsondecode(fread(fid,inf,'*char')');
        fclose(fid);
        for k = 1:numel(brgb(idx).SpatialReferencing)
            brgb(idx).SpatialReferencing(k).XWorldLimits = [imageryStructs(idx).bbox(1) imageryStructs(idx).bbox(3)]; % Longitude limits
            brgb(idx).SpatialReferencing(k).YWorldLimits = [imageryStructs(idx).bbox(2) imageryStructs(idx).bbox(4)]; % Latitude limits
        end
    end
    clear bimg]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Then, we are opening the GeoJSON file of each region with test labels, reading it, and decoding the files using the </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/matlab/ref/jsondecode.html"><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>jsondecode</w:t></w:r></w:hyperlink><w:r><w:t> function.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    for idx = 1:numel(regionNames)
        fid = fopen("test-" + regionNames(idx) + ".geojson");
        testStructs(idx) = jsondecode(fread(fid,inf,'*char')');
        fclose(fid);
    end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Once we have all the values in the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>testStructs</w:t></w:r><w:r><w:t> array we will concatenate all the structures together and get a total number of test set elements.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    numTestRegions = arrayfun(@(x)sum(length(x.features)), testStructs);
    numTestRegionsCumulative = cumsum(numTestRegions);
    numTest = sum(numTestRegions);
    testStruct = cat(1, testStructs.features);]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Now let's create placeholder arrays for the ID and coordinates</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    testID = cell(numTest,1);         % Test data ID
    testCoords = cell(numTest,1);     % Test data coordinates]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>  Loop through all test data elements</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    regionIdx = 1;
    for k = 1:numTest]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>  Extract the ID and coordinates of each ROI</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[        testID{k} = testStruct(k).id;
        coords = testStruct(k).geometry.coordinates;
        if iscell(coords)
            coords = coords{1};
        end
        testCoords{k} = squeeze(coords);]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Increment the index of regions as we loop through the training set to ensure we are referring to the correct region</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[        if k > numTestRegionsCumulative(regionIdx)
            regionIdx = regionIdx + 1;
        end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Correct for coordinate convention by flipping the Y image coordinates of the building region coordinates</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[        testCoords{k}(:,2) = brgb(regionIdx).SpatialReferencing(1).YWorldLimits(2)-(testCoords{k}(:,2)-brgb(regionIdx).SpatialReferencing(1).YWorldLimits(1));
    end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Clear the test data structures since they have now been parsed into individual arrays.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    clear testStruct testStructs]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Extract training images based on the ROIs and save each image to its corresponding material subfolder (NOTE: This will take some time)</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    regionIdx = 1;
    for k = 1:numTest]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Increment the index of regions as we loop through the test set to ensure we are referring to the correct image file when extracting regions.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[        if k > numTestRegionsCumulative(regionIdx)
            regionIdx = regionIdx + 1;
        end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>In this step, we are simply getting the lower left and upper right coordinates of the building polygon and cropping out a rectangular region, but you may feel free to try other ways to manipulate the image to extract individual buildings for test.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[        coords = testCoords{k};
        regionImg = getRegion(brgb(regionIdx),1,[min(coords(:,1)) min(coords(:,2))],[max(coords(:,1)) max(coords(:,2))]);
        imgFilename = fullfile("test_data", testID{k}+".png" );
        imwrite(regionImg,imgFilename);
    end]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Save the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>testID</w:t></w:r><w:r><w:t> and </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>testCoords</w:t></w:r><w:r><w:t> variables to a MAT-file to refer to them later without regenerating all the test data.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[    save(fullfile("test_data","test_data"),"testID","testCoords")
end]]></w:t></w:r></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="center"/></w:pPr><w:r><w:t>EXPLORING THE DATA</w:t></w:r></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Create Image Datastore from Saved Training Images</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>First we will create an </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/matlab/ref/matlab.io.datastore.imagedatastore.html"><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>imageDatastore</w:t></w:r></w:hyperlink><w:r><w:t> for the training_data folder. This is used to manage a collection of image files, where each individual image fits in memory, but the entire collection of images does not necessarily fit. </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>To further augment and preprocess the data images we recommend looking at the following resources:</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="ListParagraph"/><w:numPr><w:numId w:val="1"/></w:numPr><w:jc w:val="left"/></w:pPr><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/deeplearning/ug/preprocess-images-for-deep-learning.html"><w:r><w:t>Preprocess Images for Deep Learning</w:t></w:r></w:hyperlink></w:p><w:p><w:pPr><w:pStyle w:val="ListParagraph"/><w:numPr><w:numId w:val="1"/></w:numPr><w:jc w:val="left"/></w:pPr><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/deeplearning/examples/image-augmentation-using-image-processing-toolbox.html"><w:r><w:t>Augment Images for Deep Learning Workflows Using Image Processing Toolbox</w:t></w:r></w:hyperlink></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[imds = imageDatastore("training_data","IncludeSubfolders",true, ...
    "FileExtensions",".png","LabelSource","foldernames")]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Show a count of the distribution of all 5 materials. Notice that the number of samples for each material can be quite different, which means the classes are not balanced. This could affect the performance of your model if you do not address this, since this may bias the model to predict materials that are more frequent in the training set.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[labelInfo = countEachLabel(imds)]]></w:t></w:r></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="center"/></w:pPr><w:r><w:t>TRAINING A NEURAL NETWORK USING TRANSFER LEARNING</w:t></w:r></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Configure Pretrained Network for Transfer Learning</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>In this example we use the </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/deeplearning/ref/resnet18.html"><w:r><w:t>ResNet-18 neural network</w:t></w:r></w:hyperlink><w:r><w:t> as a baseline for our classifier. You can also use other networks to perform </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/deeplearning/examples/train-deep-learning-network-to-classify-new-images.html"><w:r><w:t>transfer learning</w:t></w:r></w:hyperlink><w:r><w:t>. </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:rPr><w:i/></w:rPr><w:t>NOTE: You will first have to download the Deep Learning Toolbox Model for ResNet-18 Network support package.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[net = resnet18;]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>To retrain ResNet-18 to classify new images, replace the last fully connected layer and the final classification layer of the network. In ResNet-18, these layers have the names </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>'fc1000'</w:t></w:r><w:r><w:t> and </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>'ClassificationLayer_predictions'</w:t></w:r><w:r><w:t>, respectively. Set the new fully connected layer to have the same size as the number of classes in the new data set. To learn faster in the new layers than in the transferred layers, increase the learning rate factors of the fully connected layer using the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>'WeightLearnRateFactor'</w:t></w:r><w:r><w:t> and </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>'BiasLearnRateFactor'</w:t></w:r><w:r><w:t> properties.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[numClasses = numel(categories(imds.Labels));
lgraph = layerGraph(net);

newFCLayer = fullyConnectedLayer(numClasses,'Name','new_fc','WeightLearnRateFactor',10,'BiasLearnRateFactor',10);
lgraph = replaceLayer(lgraph,'fc1000',newFCLayer);

newClassLayer = classificationLayer('Name','new_classoutput');
lgraph = replaceLayer(lgraph,'ClassificationLayer_predictions',newClassLayer);]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>View the modified network using the </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/deeplearning/ref/analyzenetwork.html"><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>analyzeNetwork</w:t></w:r></w:hyperlink><w:r><w:t> function. You can also open it using the </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/deeplearning/ref/deepnetworkdesigner-app.html"><w:r><w:t>Deep Network Designer app</w:t></w:r></w:hyperlink><w:r><w:t>.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[analyzeNetwork(lgraph);]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="center"/></w:pPr><w:customXml w:element="image"><w:customXmlPr><w:attr w:name="height" w:val="378"/><w:attr w:name="width" w:val="548"/><w:attr w:name="relationshipId" w:val="rId3"/></w:customXmlPr></w:customXml></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Set up training options</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Configure the image datastore to use the neural network's required input image size. To do this, we are registering a custom function called </w:t></w:r><w:hyperlink w:anchor="internal:959032C0"><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>readAndResize</w:t></w:r></w:hyperlink><w:r><w:t> (which you can find at the end of this script) and setting it as the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>ReadFcn</w:t></w:r><w:r><w:t> in the datastore.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[inputSize = net.Layers(1).InputSize;
imds.ReadFcn = @(im)readAndResize(im,inputSize); % Refers to a helper function at the end of this script]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Split the training data into training and validation sets. Note that this is randomly selecting a split, but you may want to look into the </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/matlab/ref/matlab.io.datastore.imagedatastore.spliteachlabel.html"><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>splitEachLabel</w:t></w:r></w:hyperlink><w:r><w:t> function for other options to make sure the classes are balanced</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[[imdsTrain,imdsVal] = splitEachLabel(imds,0.7,"randomized");]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Specify the training options, including mini-batch size and validation data. Set</w:t></w:r><w:r><w:t> </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>InitialLearnRate</w:t></w:r><w:r><w:t> </w:t></w:r><w:r><w:t>to a small value to slow down learning in the transferred layers. In the previous step, you increased the learning rate factors for the fully connected layer to speed up learning in the new final layers. This combination of learning rate settings results in fast learning only in the new layers and slower learning in the other layers.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>You can work with different options to improve the training. Check out the </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/deeplearning/ref/trainingoptions.html"><w:r><w:t>documentation for trainingOptions</w:t></w:r></w:hyperlink><w:r><w:t> to learn more.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[options = trainingOptions('sgdm', ...
    'MiniBatchSize',32, ...
    'MaxEpochs',5, ...
    'InitialLearnRate',1e-4, ...
    'Shuffle','every-epoch', ...
    'ValidationData',imdsVal, ...
    'ValidationFrequency',floor(numel(imdsTrain.Files)/(32*2)), ...
    'Verbose',false, ...
    'Plots','training-progress');]]></w:t></w:r></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Train the network</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Here you will use the image datastores, neural network layer graph, and training options to train your model.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Note that training will take a long time using a CPU. However, MATLAB will automatically detect if you have a </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/parallel-computing/gpu-support-by-release.html"><w:r><w:t>supported GPU</w:t></w:r></w:hyperlink><w:r><w:t> to help you accelerate training.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Set the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>doTraining</w:t></w:r><w:r><w:t> flag below to </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>false</w:t></w:r><w:r><w:t> to load a presaved network.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[doTraining = false;
if doTraining
    netTransfer = trainNetwork(imdsTrain,lgraph,options);
else
    load resnet_presaved.mat
end
]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="center"/></w:pPr><w:customXml w:element="image"><w:customXmlPr><w:attr w:name="height" w:val="620"/><w:attr w:name="width" w:val="1000"/><w:attr w:name="relationshipId" w:val="rId4"/></w:customXmlPr></w:customXml></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="center"/></w:pPr><w:r><w:t>PREDICTING &amp; SUBMITTING</w:t></w:r></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Predict on the Test Set</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Once we have our trained network, we can perform predictions on our test set. To do so, first we will create an image datastore for the test set.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[imdsTest = imageDatastore("test_data","FileExtensions",".png");
imdsTest.ReadFcn = @(im)readAndResize(im,inputSize)]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Next we predict labels (</w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>testMaterial)</w:t></w:r><w:r><w:t> and scores (</w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>testScores</w:t></w:r><w:r><w:t>) using the trained network </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>NOTE: This will take some time, but just as with training the network, MATLAB will determine whether you have a supported GPU and significantly speed up this process.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[[testMaterial,testScores] = classify(netTransfer,imdsTest)]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>The following code will display the predicted materials for a few test images. You need to change the </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>display</w:t></w:r><w:r><w:t> flag to </w:t></w:r><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>true</w:t></w:r><w:r><w:t> to execute the below code. </w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[figure
displayIndices = randi(numTest,4,1);
for k = 1:numel(displayIndices)
    testImg = readimage(imdsTest,displayIndices(k));
    subplot(2,2,k)
    imshow(testImg);
    title(string(testMaterial(displayIndices(k))),"Interpreter","none")
end]]></w:t></w:r></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><mc:AlternateContent xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006"><mc:Choice Requires="R2018b"><w:pPr><w:pStyle w:val="heading2"/><w:jc w:val="left"/></w:pPr></mc:Choice><mc:Fallback><w:pPr><w:pStyle w:val="heading"/><w:jc w:val="left"/></w:pPr></mc:Fallback></mc:AlternateContent><w:r><w:t>Save Submission to File</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Create a table of the results based on the IDs and prediction scores. The desired file format for submission is:</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:rPr><w:rFonts w:cs="monospace"/></w:rPr><w:t>id, concrete_cement, healthy_metal, incomplete, irregular_metal, other</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>We will place all the test results in a MATLAB table, which makes it easy to visualize and to write to the desired file format.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[testResults = table(testID,testScores(:,1),testScores(:,2), ...
    testScores(:,3),testScores(:,4),testScores(:,5), ...
    'VariableNames',['id';categories(testMaterial)])]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Write the results to a CSV file. This is the file you will submit for the challenge.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:r><w:t><![CDATA[writetable(testResults,'testResults.csv');]]></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Thanks for following along with this code! We are excited to find out how you will modify this starter code and make it yours. We strongly recommend looking at our </w:t></w:r><w:hyperlink w:docLocation="https://www.mathworks.com/help/releases/R2019b/deeplearning/ug/deep-learning-tips-and-tricks.html"><w:r><w:t>Deep Learning Tips &amp; Tricks page</w:t></w:r></w:hyperlink><w:r><w:t> for more ideas on how you can improve our benchmark model.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Feel free to reach out to us in the DrivenData forum or email us at studentcompetitions@mathworks.com if you have any further questions.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t></w:t></w:r></w:p><w:p><w:pPr><w:sectPr/></w:pPr></w:p><w:p><w:pPr><w:pStyle w:val="title"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Helper Functions</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Separates a bigimage into its RGB (1st to 3rd) and mask (4th) channels.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:bookmarkStart w:name="MW_354E232C" w:id="354E232C"/><w:r><w:t><![CDATA[function [rgb, m] = separateChannels(rgbm)
rgb = rgbm(:,:,1:3);
m = logical(rgbm(:,:,4));
end]]></w:t></w:r><w:bookmarkEnd w:id="354E232C"/></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t>Read and resize an image to a desired input size</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="code"/></w:pPr><w:bookmarkStart w:name="MW_959032C0" w:id="959032C0"/><w:r><w:t><![CDATA[function im = readAndResize(filename,sz)
im = imresize( imread(filename), sz(1:2) );
end]]></w:t></w:r><w:bookmarkEnd w:id="959032C0"/></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:rPr><w:i/></w:rPr><w:t></w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:rPr><w:i/></w:rPr><w:t>Copyright 2019 The MathWorks, Inc.</w:t></w:r></w:p><w:p><w:pPr><w:pStyle w:val="text"/><w:jc w:val="left"/></w:pPr><w:r><w:t></w:t></w:r></w:p></w:body></w:document>